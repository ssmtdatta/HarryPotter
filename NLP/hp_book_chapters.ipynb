{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code:  \n",
    "* reads text files for each book  \n",
    "* cleans and formats each book - expand contraction words according to specification of \"contractions_dictionary.p\"  \n",
    "* splits books in chapters  \n",
    "* saves each book as a dictionary (key=chapter_number, value = chapter as a string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.tokenize import WhitespaceTokenizer, RegexpTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import sys\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"/Users/susmitadatta/Metis/Proj04/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.append(path.abspath(BASE_DIR+'NLP/SupportModules/'))\n",
    "import data_transform_module as dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "contractions_dictionary = dtm.unpickleSomething(BASE_DIR+'NLP/SupportData/', \"contractions_dictionary.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SCRIPT_PATH = BASE_DIR+\"Book_Scripts/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expand_contractions(s, contractions_dictionary=contractions_dictionary):\n",
    "    contractions_re = re_compile(contractions_dictionary)\n",
    "    def replace(match):\n",
    "        return contractions_dictionary[match.group(0)]\n",
    "    return contractions_re.sub(replace, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bookChapters(book_str):\n",
    "    book_chapters = []\n",
    "    chapters = book_str.split(\"CHAPTER\")\n",
    "    for chap in chapters:\n",
    "        if len(chap) > 1000:\n",
    "            book_chapters.append(chap)\n",
    "    return book_chapters\n",
    "    \n",
    "def bookScript(seq):\n",
    "    script_name = \"book{}.txt\".format(seq)\n",
    "    script_str = script2String(SCRIPT_PATH, script_name)\n",
    "    return script_str\n",
    "\n",
    "def re_bookChapters(book_chapters):\n",
    "    book_chapters = list(map(lambda x: expand_contractions(x), book_chapters))\n",
    "    book_chapters = list(map(lambda x: re.sub(r'\\s+', \" \", x), book_chapters))\n",
    "    book_chapters = list(map(lambda x: re.sub('[^a-zA-Z]', \" \", x), book_chapters))\n",
    "    return book_chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book1 has 17 chapters\n",
      "Book2 has 18 chapters\n",
      "Book3 has 22 chapters\n",
      "Book4 has 37 chapters\n",
      "Book5 has 38 chapters\n",
      "Book6 has 31 chapters\n",
      "Book7 has 43 chapters\n"
     ]
    }
   ],
   "source": [
    "hp_series = range(1, 8)\n",
    "for seq in hp_series:\n",
    "\n",
    "    book_str = bookScript(seq) # read a book as a string\n",
    "    book_chapters = bookChapters(book_str) # list chapter, each chapter is a string\n",
    "    book_chapters = re_bookChapters(book_chapters) # clean up the chapters\n",
    "    \n",
    "    book_dictionary = {}\n",
    "    for i in range(0, len(book_chapters)):\n",
    "        book_dictionary[i] = book_chapters[i]        \n",
    "    print(\"Book{} has\".format(seq), len(book_dictionary), \"chapters\")\n",
    "    \n",
    "    pickle_filename = \"book{}_chapters.p\".format(seq)\n",
    "    dtm.pickleSomething(book_dictionary, \n",
    "                    BASE_DIR+\"NLP/BookData/\", \n",
    "                    pickle_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
